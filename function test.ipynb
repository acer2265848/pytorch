{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.visualization import plot_gasf,plot_gadf,plot_mtf,plot_recurrence_plots\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rainbow TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pyts.visualization import plot_gasf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "pre_path = \"color_wafer_img\"\n",
    "# pre_path = \"wafer_img\"\n",
    "is_whole=True\n",
    "is_cross =True\n",
    "method = \"mtf\"\n",
    "cross_number_for_test =1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if is_whole==True:\n",
    "    whole=\"_all\"\n",
    "else:\n",
    "    whole=\"\"\n",
    "cross=[\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "cross.remove(str(cross_number_for_test))\n",
    "x = [  \n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[0]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[1]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[2]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[3]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[0]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[1]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[2]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[3]+\".json\")\n",
    "]\n",
    "x = pd.concat(x)\n",
    "x =  x.sample(frac=1)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('P')\n",
    "lst = list()\n",
    "count=0\n",
    "lst2=list()\n",
    "y=list()\n",
    "\n",
    "for i in x.batch.unique():\n",
    "    df=x[x.batch==i]\n",
    "    lst = list()\n",
    "    if np.all(df.status==\"abnormal\"):\n",
    "        path=\"wafer_img_cross\"+whole+\"/\"+method+\"/\"+str(df.iloc[0].cross)+\"/abnormal/\"\n",
    "    else:\n",
    "        path=\"wafer_img_cross\"+whole+\"/\"+method+\"/\"+str(df.iloc[0].cross)+\"/normal/\"\n",
    "\n",
    "    list_im = [\n",
    "        path+str(i)+'_11.png', \n",
    "        path+str(i)+'_12.png', \n",
    "        path+str(i)+'_15.png', \n",
    "        path+str(i)+'_6.png', \n",
    "        path+str(i)+'_7.png', \n",
    "        path+str(i)+'_8.png', \n",
    "    ]\n",
    "    imgs = [ pil_loader(i) for i in list_im ]\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.vstack( (np.asarray(i) for i in imgs ) )\n",
    "    imgs_comb = np.array( imgs_comb)\n",
    "    lst.append(np.array(imgs_comb)/255)\n",
    "\n",
    "    arr = np.array(lst)\n",
    "    if df.iloc[0].status==\"normal\":\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "\n",
    "    lst2.append(arr)    \n",
    "#     count+=1\n",
    "#     if count==1:\n",
    "#         break\n",
    "train_x = torch.from_numpy(np.array(lst2)).float()\n",
    "train_y = torch.LongTensor(np.array(y))\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ...,   0,   0,   0],\n",
       "       [255, 255, 255, ...,   0,   0,   0],\n",
       "       [255, 255, 255, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [255, 255, 255, ...,   8,   8,   8],\n",
       "       [255, 255, 255, ...,   8,   8,   8],\n",
       "       [255, 255, 255, ...,   8,   8,   8]], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_comb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL.Image\n",
    "image = PIL.Image.open('wafer_img_cross_all/mtf/2/normal/186105_11.png')\n",
    "import numpy as np\n",
    "image = np.asarray(image).shape\n",
    "# image.shape\n",
    "# image[...,:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255]],\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255]],\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255],\n",
       "        [204, 204, 204, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import torch.nn as nn\n",
    "\n",
    "accuracy_matrix =[]\n",
    "for i in range(5):\n",
    "    min_error=100\n",
    "    min_lose=100\n",
    "    count=0\n",
    "    number=1\n",
    "#     cross = dataset_six_combine_method.dataset_dataloader(True,True,\"mtf\",\"gasf\",i+1)\n",
    "#     cross = dataset_combine_method.dataset_dataloader(True,True,\"mtf\",\"mtf\",i+1)\n",
    "    cross = dataset.dataset_dataloader(\"\",True,True,\"gasf\",i+1)\n",
    "    \n",
    "    EPOCH = 50              # train the training data n times, to save time, we just train 1 epoch\n",
    "    LR = 0.0023\n",
    "    \n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.conv1 =nn.Sequential( #卷基層   \n",
    "                nn.Conv2d(\n",
    "                    in_channels  = 1  , # 圖片是有幾層的 若 RGB三層 灰階 1層\n",
    "                    out_channels = 10, # 同時有幾個filter 進行掃描 會提取擠個特徵 代表下一層高度為擠\n",
    "                    kernel_size  = 5  , # 一次畫出來的框 畫幾格 ex 5*5\n",
    "                    stride       = 1  , # 每一個框框跳幾格\n",
    "                    padding      = 2, # 在 5x5逐步掃描後會有少的格子 因此2代表在外面為兩圈的0\n",
    "                                        # if stride =1 padding = (kernel_size-1)/2\n",
    "                ),  # 過濾器 卷基層 蒐集圖片訊息 三維的空間  \n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2), #找出更重要的特徵  像是在2x2中 找到 最大的值\n",
    "            )                                # -> (16,64,64)\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(10,20,5,1,2), # 輸入的是上一層的16 把輸出層在變大因此是32 其他不變\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)             # -> (16,32,32)\n",
    "            )\n",
    "#             self.conv3 = nn.Sequential(\n",
    "#                 nn.Conv2d(5,10,5,1,2), # 輸入的是上一層的16 把輸出層在變大因此是32 其他不變\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(2)\n",
    "#             )\n",
    "\n",
    "            self.out = nn.Linear(20*192*32,2)\n",
    "        def forward(self,x):\n",
    "\n",
    "            x=self.conv1(x)\n",
    "            x=self.conv2(x) #(batch.32.7.7)\n",
    "#             x=self.conv3(x)\n",
    "            x=x.view(x.size(0),-1) #將三維轉二維 (batch , 32*7*7)\n",
    "            output=self.out(x)\n",
    "            return output,x\n",
    "\n",
    "    cnn=CNN()\n",
    "    cnn.cuda()\n",
    "#     print(cnn)\n",
    "\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "    loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "    # following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "\n",
    "    # training and testing\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (x, y) in enumerate(cross.train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "#             print(step)\n",
    "            b_x = Variable(x).cuda()   # batch x\n",
    "            b_y = Variable(y).cuda()   # batch y\n",
    "#             print(\"b_x.size:\",b_x.size())\n",
    "            output = cnn(b_x)[0]             # cnn output\n",
    "            loss = loss_func(output, b_y)   # cross entropy loss\n",
    "            optimizer.zero_grad()           # clear gradients for this training step\n",
    "            loss.backward()                 # backpropagation, compute gradients\n",
    "            optimizer.step()                # apply gradients\n",
    "            test_output, last_layer = cnn(cross.test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()\n",
    "            accuracy = sum(pred_y == cross.test_y).item() / float(cross.test_y.size(0))\n",
    "            error  = (1-accuracy)*100\n",
    "            \n",
    "            if error<min_error:\n",
    "                min_error=error\n",
    "                min_lose=100\n",
    "                count=0\n",
    "            else:\n",
    "                count+=1\n",
    "                print(\".\",end=\"\")\n",
    "\n",
    "            if error == min_error:\n",
    "                if loss.data.item()<min_lose:\n",
    "                    min_lose=loss.data.item()\n",
    "#                     torch.save(cnn,'cnn_save/cnn'+str(number)+'.pkl')\n",
    "                    number+=1\n",
    "    #                 print('save!!')\n",
    "    #                 print('\\ncount: ',count,'Epoch: ', epoch, '| train loss: %.15f' % loss.data[0], '| min validation error rate: %.20f' % min_error)\n",
    "            if count>=350:\n",
    "                break\n",
    "        if count>=350:\n",
    "            break\n",
    "    print(\"min_error:\",min_error)\n",
    "    # print 10 predictions from test data\n",
    "    # test_output, _ = cnn(test_x)\n",
    "    # pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()\n",
    "\n",
    "    # print(pred_y, 'prediction number')\n",
    "    # print(test_y, 'real number')\n",
    "    accuracy_matrix.append(min_error)\n",
    "    print('\\n number: ',number-1 ,min_error)\n",
    "    \n",
    "import IPython.display as ipd\n",
    "import numpy\n",
    "sr = 22050 # sample rate\n",
    "T = 0.3    # seconds\n",
    "t = numpy.linspace(0, T, int(T*sr), endpoint=False) # time variable\n",
    "x = 0.5*numpy.sin(2*numpy.pi*490*t)                # pure sine wave at 440 284Hz\n",
    "ipd.Audio(x, rate=sr,autoplay=True) # load a NumPy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hstack RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pyts.visualization import plot_gasf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "pre_path = \"color_\"\n",
    "# pre_path = \"wafer_img\"\n",
    "is_whole=True\n",
    "is_cross =True\n",
    "method = \"mtf\"\n",
    "cross_number_for_test =1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if is_whole==True:\n",
    "    whole=\"_all\"\n",
    "else:\n",
    "    whole=\"\"\n",
    "cross=[\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "cross.remove(str(cross_number_for_test))\n",
    "x = [  \n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[0]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[1]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[2]+\".json\"),\n",
    "    pd.read_json(\"normal\"+whole+\"_cross_\"+cross[3]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[0]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[1]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[2]+\".json\"),\n",
    "    pd.read_json(\"abnormal\"+whole+\"_cross_\"+cross[3]+\".json\")\n",
    "]\n",
    "x = pd.concat(x)\n",
    "x =  x.sample(frac=1)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "lst = list()\n",
    "count=0\n",
    "lst2=list()\n",
    "y=list()\n",
    "\n",
    "for i in x.batch.unique():\n",
    "    df=x[x.batch==i]\n",
    "    lst = list()\n",
    "    if np.all(df.status==\"abnormal\"):\n",
    "        path=pre_path+\"wafer_img_cross\"+whole+\"/\"+method+\"/\"+str(df.iloc[0].cross)+\"/abnormal/\"\n",
    "    else:\n",
    "        path=pre_path+\"wafer_img_cross\"+whole+\"/\"+method+\"/\"+str(df.iloc[0].cross)+\"/normal/\"\n",
    "\n",
    "    list_im = [\n",
    "        path+str(i)+'_11.png', \n",
    "        path+str(i)+'_12.png', \n",
    "        path+str(i)+'_15.png', \n",
    "        path+str(i)+'_6.png', \n",
    "        path+str(i)+'_7.png', \n",
    "        path+str(i)+'_8.png', \n",
    "    ]\n",
    "    imgs = [ pil_loader(i) for i in list_im ]\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    for k in range(3):\n",
    "        imgs_comb = [np.asarray(i) for i in imgs]\n",
    "        imgs_comb = np.vstack( (i[:,:,k] for i in imgs_comb ) )\n",
    "        imgs_comb = np.array( imgs_comb)\n",
    "        lst.append(np.array(imgs_comb)/255)\n",
    "        \n",
    "    lst3 = list()\n",
    "    imgs_Hcomb = np.hstack( (i for i in lst ) )\n",
    "    lst3.append(imgs_Hcomb)\n",
    "    lst3 = np.array(lst3)\n",
    "    \n",
    "    arr = np.array(lst3)\n",
    "    if df.iloc[0].status==\"normal\":\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "\n",
    "    lst2.append(arr)    \n",
    "#     count+=1\n",
    "#     if count==1:\n",
    "#         break\n",
    "train_x = torch.from_numpy(np.array(lst2)).float()\n",
    "train_y = torch.LongTensor(np.array(y))\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768, 384)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst3 = list()\n",
    "imgs_Hcomb = np.hstack( (i for i in lst ) )\n",
    "lst3.append(imgs_Hcomb)\n",
    "ss = np.array(lst3)\n",
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
